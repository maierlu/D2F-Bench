SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/spark/lib/spark-assembly-1.4.1.2.3.2.0-2950-hadoop2.7.1.2.3.2.0-2950.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/spark/lib/spark-assembly-1.4.1.2.3.2.0-2950-hadoop2.7.1.2.3.2.0-2950.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

Logging initialized using configuration in file:/etc/hive/2.3.2.0-2950/0/hive-log4j.properties
OK
Time taken: 2.166 seconds
OK
Time taken: 5.408 seconds
OK
Time taken: 0.255 seconds
OK
Time taken: 6.758 seconds
Query ID = root_20151217153102_20e302ae-a42a-4d60-875c-9080022cccc7
Total jobs = 8
Launching Job 1 out of 8
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1450357971950_0098, Tracking URL = http://sandbox.hortonworks.com:8088/proxy/application_1450357971950_0098/
Kill Command = /usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop job  -kill job_1450357971950_0098
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 6
2015-12-17 15:31:20,375 Stage-1 map = 0%,  reduce = 0%
2015-12-17 15:31:43,190 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 12.82 sec
2015-12-17 15:31:51,787 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 23.47 sec
2015-12-17 15:31:55,014 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.95 sec
2015-12-17 15:32:17,449 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 30.92 sec
2015-12-17 15:32:21,271 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 37.75 sec
2015-12-17 15:32:25,871 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 47.55 sec
2015-12-17 15:32:29,756 Stage-1 map = 100%,  reduce = 70%, Cumulative CPU 59.98 sec
2015-12-17 15:32:31,019 Stage-1 map = 100%,  reduce = 71%, Cumulative CPU 63.17 sec
2015-12-17 15:32:32,384 Stage-1 map = 100%,  reduce = 79%, Cumulative CPU 66.2 sec
2015-12-17 15:32:34,937 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 69.61 sec
2015-12-17 15:32:37,320 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 74.29 sec
2015-12-17 15:32:38,545 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 85.27 sec
2015-12-17 15:32:41,062 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 90.44 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 440 msec
Ended Job = job_1450357971950_0098
WARNING: Use "yarn jar" to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.3.2.0-2950/spark/lib/spark-assembly-1.4.1.2.3.2.0-2950-hadoop2.7.1.2.3.2.0-2950.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/root/root_20151217153102_20e302ae-a42a-4d60-875c-9080022cccc7.log
2015-12-17 15:32:52	Starting to launch local task to process map join;	maximum memory = 255328256
2015-12-17 15:32:56	Processing rows:	200000	Hashtable size:	199999	Memory usage:	73409032	percentage:	0.288
2015-12-17 15:32:57	Processing rows:	300000	Hashtable size:	299999	Memory usage:	103753312	percentage:	0.406
2015-12-17 15:32:57	Dump the side-table for tag: 0 with group count: 300000 into file: file:/tmp/root/c8191bc2-8c94-4cda-a284-ee61a8b4d1f2/hive_2015-12-17_15-31-02_842_4813002057978073220-1/-local-10014/HashTable-Stage-13/MapJoin-mapfile30--.hashtable
2015-12-17 15:32:57	Uploaded 1 File to: file:/tmp/root/c8191bc2-8c94-4cda-a284-ee61a8b4d1f2/hive_2015-12-17_15-31-02_842_4813002057978073220-1/-local-10014/HashTable-Stage-13/MapJoin-mapfile30--.hashtable (13433699 bytes)
2015-12-17 15:32:57	End of local task; Time Taken: 5.382 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 8
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1450357971950_0099, Tracking URL = http://sandbox.hortonworks.com:8088/proxy/application_1450357971950_0099/
Kill Command = /usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop job  -kill job_1450357971950_0099
Hadoop job information for Stage-13: number of mappers: 1; number of reducers: 0
2015-12-17 15:33:09,904 Stage-13 map = 0%,  reduce = 0%
2015-12-17 15:33:28,173 Stage-13 map = 50%,  reduce = 0%, Cumulative CPU 24.81 sec
2015-12-17 15:33:34,591 Stage-13 map = 100%,  reduce = 0%, Cumulative CPU 31.63 sec
MapReduce Total cumulative CPU time: 31 seconds 630 msec
Ended Job = job_1450357971950_0099
Stage-14 is filtered out by condition resolver.
Stage-15 is filtered out by condition resolver.
Stage-16 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 3 out of 8
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1450357971950_0100, Tracking URL = http://sandbox.hortonworks.com:8088/proxy/application_1450357971950_0100/
Kill Command = /usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop job  -kill job_1450357971950_0100
Hadoop job information for Stage-2: number of mappers: 3; number of reducers: 9
2015-12-17 15:33:44,524 Stage-2 map = 0%,  reduce = 0%
2015-12-17 15:34:00,486 Stage-2 map = 33%,  reduce = 0%, Cumulative CPU 3.87 sec
2015-12-17 15:34:27,201 Stage-2 map = 33%,  reduce = 2%, Cumulative CPU 44.01 sec
2015-12-17 15:34:29,578 Stage-2 map = 33%,  reduce = 5%, Cumulative CPU 48.81 sec
2015-12-17 15:34:30,721 Stage-2 map = 33%,  reduce = 6%, Cumulative CPU 52.06 sec
2015-12-17 15:34:44,940 Stage-2 map = 48%,  reduce = 6%, Cumulative CPU 78.96 sec
2015-12-17 15:34:55,299 Stage-2 map = 59%,  reduce = 6%, Cumulative CPU 102.44 sec
2015-12-17 15:34:57,454 Stage-2 map = 67%,  reduce = 6%, Cumulative CPU 106.25 sec
2015-12-17 15:35:01,018 Stage-2 map = 69%,  reduce = 6%, Cumulative CPU 112.79 sec
2015-12-17 15:35:04,549 Stage-2 map = 70%,  reduce = 6%, Cumulative CPU 120.76 sec
2015-12-17 15:35:06,802 Stage-2 map = 73%,  reduce = 6%, Cumulative CPU 123.29 sec
2015-12-17 15:35:10,013 Stage-2 map = 76%,  reduce = 6%, Cumulative CPU 128.8 sec
2015-12-17 15:35:11,100 Stage-2 map = 78%,  reduce = 6%, Cumulative CPU 133.81 sec
2015-12-17 15:35:13,391 Stage-2 map = 78%,  reduce = 10%, Cumulative CPU 134.44 sec
2015-12-17 15:35:14,473 Stage-2 map = 78%,  reduce = 11%, Cumulative CPU 138.58 sec
2015-12-17 15:35:15,528 Stage-2 map = 78%,  reduce = 12%, Cumulative CPU 138.78 sec
2015-12-17 15:35:23,154 Stage-2 map = 89%,  reduce = 12%, Cumulative CPU 149.43 sec
2015-12-17 15:35:26,473 Stage-2 map = 89%,  reduce = 15%, Cumulative CPU 153.2 sec
2015-12-17 15:35:29,710 Stage-2 map = 90%,  reduce = 15%, Cumulative CPU 156.55 sec
2015-12-17 15:35:32,192 Stage-2 map = 91%,  reduce = 15%, Cumulative CPU 159.36 sec
2015-12-17 15:35:35,658 Stage-2 map = 92%,  reduce = 15%, Cumulative CPU 162.59 sec
2015-12-17 15:35:41,561 Stage-2 map = 93%,  reduce = 15%, Cumulative CPU 167.63 sec
2015-12-17 15:35:44,800 Stage-2 map = 94%,  reduce = 15%, Cumulative CPU 170.63 sec
2015-12-17 15:35:48,026 Stage-2 map = 96%,  reduce = 15%, Cumulative CPU 173.67 sec
2015-12-17 15:35:50,260 Stage-2 map = 97%,  reduce = 15%, Cumulative CPU 176.2 sec
2015-12-17 15:35:53,454 Stage-2 map = 99%,  reduce = 15%, Cumulative CPU 179.6 sec
2015-12-17 15:35:55,651 Stage-2 map = 100%,  reduce = 15%, Cumulative CPU 181.77 sec
2015-12-17 15:35:56,927 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 183.51 sec
2015-12-17 15:35:58,361 Stage-2 map = 100%,  reduce = 19%, Cumulative CPU 184.92 sec
2015-12-17 15:35:59,651 Stage-2 map = 100%,  reduce = 21%, Cumulative CPU 186.2 sec
2015-12-17 15:36:01,002 Stage-2 map = 100%,  reduce = 38%, Cumulative CPU 191.94 sec
2015-12-17 15:36:02,454 Stage-2 map = 100%,  reduce = 41%, Cumulative CPU 193.26 sec
2015-12-17 15:36:03,862 Stage-2 map = 100%,  reduce = 44%, Cumulative CPU 196.98 sec
2015-12-17 15:36:16,737 Stage-2 map = 100%,  reduce = 45%, Cumulative CPU 211.18 sec
2015-12-17 15:36:19,172 Stage-2 map = 100%,  reduce = 46%, Cumulative CPU 232.4 sec
2015-12-17 15:36:20,362 Stage-2 map = 100%,  reduce = 47%, Cumulative CPU 235.44 sec
2015-12-17 15:36:21,503 Stage-2 map = 100%,  reduce = 48%, Cumulative CPU 236.77 sec
2015-12-17 15:36:22,860 Stage-2 map = 100%,  reduce = 50%, Cumulative CPU 242.12 sec
2015-12-17 15:36:24,206 Stage-2 map = 100%,  reduce = 66%, Cumulative CPU 248.37 sec
2015-12-17 15:36:25,442 Stage-2 map = 100%,  reduce = 68%, Cumulative CPU 252.69 sec
2015-12-17 15:36:26,734 Stage-2 map = 100%,  reduce = 69%, Cumulative CPU 255.87 sec
2015-12-17 15:36:27,956 Stage-2 map = 100%,  reduce = 70%, Cumulative CPU 258.03 sec
2015-12-17 15:36:29,406 Stage-2 map = 100%,  reduce = 72%, Cumulative CPU 262.34 sec
2015-12-17 15:36:30,767 Stage-2 map = 100%,  reduce = 73%, Cumulative CPU 264.35 sec
2015-12-17 15:36:32,018 Stage-2 map = 100%,  reduce = 75%, Cumulative CPU 267.46 sec
2015-12-17 15:36:33,290 Stage-2 map = 100%,  reduce = 76%, Cumulative CPU 269.93 sec
2015-12-17 15:36:34,691 Stage-2 map = 100%,  reduce = 78%, Cumulative CPU 273.37 sec
2015-12-17 15:36:35,982 Stage-2 map = 100%,  reduce = 79%, Cumulative CPU 275.81 sec
2015-12-17 15:36:37,196 Stage-2 map = 100%,  reduce = 80%, Cumulative CPU 281.69 sec
2015-12-17 15:36:38,460 Stage-2 map = 100%,  reduce = 81%, Cumulative CPU 285.51 sec
2015-12-17 15:36:39,598 Stage-2 map = 100%,  reduce = 83%, Cumulative CPU 293.98 sec
2015-12-17 15:36:42,002 Stage-2 map = 100%,  reduce = 84%, Cumulative CPU 296.15 sec
2015-12-17 15:36:43,271 Stage-2 map = 100%,  reduce = 85%, Cumulative CPU 298.43 sec
2015-12-17 15:36:45,634 Stage-2 map = 100%,  reduce = 87%, Cumulative CPU 302.17 sec
2015-12-17 15:36:49,121 Stage-2 map = 100%,  reduce = 89%, Cumulative CPU 306.24 sec
2015-12-17 15:36:57,910 Stage-2 map = 100%,  reduce = 98%, Cumulative CPU 313.93 sec
2015-12-17 15:37:00,042 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 316.95 sec
MapReduce Total cumulative CPU time: 5 minutes 16 seconds 950 msec
Ended Job = job_1450357971950_0100
Launching Job 4 out of 8
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1450357971950_0101, Tracking URL = http://sandbox.hortonworks.com:8088/proxy/application_1450357971950_0101/
Kill Command = /usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop job  -kill job_1450357971950_0101
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2015-12-17 15:37:11,921 Stage-3 map = 0%,  reduce = 0%
2015-12-17 15:37:18,471 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.37 sec
2015-12-17 15:37:27,321 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 3.85 sec
MapReduce Total cumulative CPU time: 3 seconds 850 msec
Ended Job = job_1450357971950_0101
Launching Job 5 out of 8
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1450357971950_0102, Tracking URL = http://sandbox.hortonworks.com:8088/proxy/application_1450357971950_0102/
Kill Command = /usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop job  -kill job_1450357971950_0102
Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
2015-12-17 15:37:42,444 Stage-4 map = 0%,  reduce = 0%
2015-12-17 15:37:49,941 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 1.41 sec
2015-12-17 15:37:56,396 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 3.85 sec
MapReduce Total cumulative CPU time: 3 seconds 850 msec
Ended Job = job_1450357971950_0102
Moving data to: hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/tpch_orc_2sf.db/q18_large_volume_customer_cached
Table tpch_orc_2sf.q18_large_volume_customer_cached stats: [numFiles=1, numRows=100, totalSize=6056, rawDataSize=5956]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 6   Cumulative CPU: 90.44 sec   HDFS Read: 26400288 HDFS Write: 3967 SUCCESS
Stage-Stage-13: Map: 1   Cumulative CPU: 31.63 sec   HDFS Read: 27242601 HDFS Write: 201619661 SUCCESS
Stage-Stage-2: Map: 3  Reduce: 9   Cumulative CPU: 316.95 sec   HDFS Read: 228081868 HDFS Write: 9142 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 3.85 sec   HDFS Read: 16968 HDFS Write: 8454 SUCCESS
Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 3.85 sec   HDFS Read: 14456 HDFS Write: 6160 SUCCESS
Total MapReduce CPU Time Spent: 7 minutes 26 seconds 720 msec
OK
Time taken: 428.554 seconds
