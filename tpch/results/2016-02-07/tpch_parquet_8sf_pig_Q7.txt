WARNING: Use "yarn jar" to launch YARN applications.
16/02/07 17:57:48 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL
16/02/07 17:57:48 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE
16/02/07 17:57:48 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType
2016-02-07 17:57:48,318 [main] INFO  org.apache.pig.Main - Apache Pig version 0.15.0.2.3.2.0-2950 (rexported) compiled Sep 30 2015, 19:39:20
2016-02-07 17:57:48,318 [main] INFO  org.apache.pig.Main - Logging error messages to: /root/D2F-Bench/bin/pig_1454867868316.log
2016-02-07 17:57:49,342 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found
2016-02-07 17:57:49,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://sandbox.hortonworks.com:8020
2016-02-07 17:57:51,499 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
2016-02-07 17:57:52,377 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 8
2016-02-07 17:57:52,787 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 8
2016-02-07 17:57:52,951 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 8
2016-02-07 17:57:53,112 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
2016-02-07 17:57:53,193 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
2016-02-07 17:57:53,449 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2016-02-07 17:57:53,550 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2016-02-07 17:57:53,598 [main] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.
2016-02-07 17:57:53,651 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2016-02-07 17:57:53,819 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for orders: $2, $3, $4, $5, $6, $7, $8
2016-02-07 17:57:53,822 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for customer: $1, $2, $4, $5, $6, $7
2016-02-07 17:57:53,823 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for supplier: $1, $2, $4, $5, $6
2016-02-07 17:57:53,823 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for lineitem0: $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2016-02-07 17:57:53,824 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for nation20: $2, $3
2016-02-07 17:57:53,831 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2000: Error processing rule ColumnMapKeyPrune. Try -t ColumnMapKeyPrune
Details at logfile: /root/D2F-Bench/bin/pig_1454867868316.log
2016-02-07 17:57:53,855 [main] INFO  org.apache.pig.Main - Pig script completed in 5 seconds and 693 milliseconds (5693 ms)
Feb 7, 2016 5:57:51 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Feb 7, 2016 5:57:51 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:51 PM INFO: parquet.hadoop.ParquetFileReader: reading another 1 footers
Feb 7, 2016 5:57:51 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 8
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: reading another 8 footers
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 8
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: reading another 8 footers
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 8
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: reading another 8 footers
Feb 7, 2016 5:57:52 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:53 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Feb 7, 2016 5:57:53 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:53 PM INFO: parquet.hadoop.ParquetFileReader: reading another 1 footers
Feb 7, 2016 5:57:53 PM INFO: parquet.hadoop.ParquetFileReader: Initiating action with parallelism: 5
Feb 7, 2016 5:57:53 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
